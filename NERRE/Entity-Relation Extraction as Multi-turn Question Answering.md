# Abstract

在本文中，我们为实体-关系的提取任务提出了一个新的范式。我们把这个任务看作是一个多轮问题的回答问题，也就是说，实体和关系的提取被转化为从上下文中识别答案跨度的任务。

这种多轮问答的形式化有几个关键的优点：首先，问题查询编码了我们想要识别的实体/关系类的重要信息；其次，QA 提供了一种联合建模实体和关系的自然方式；第三，它允许我们利用已开发的机器阅读理解（MRC）模型。

在ACE和CoNLL04语料库上的实验表明，所提出的范式明显优于以前的最佳模型。我们能够在所有的ACE04、ACE05和CoNLL04数据集上获得最先进的结果，将这三个数据集的SOTA结果分别提高到49.4（+1.0）、60.2（+0.6）和68.9（+1.1）。

此外，我们还构建了一个新开发的中文数据集RESUME，该数据集需要多步推理来构建实体依赖关系，而不是之前数据集中三联体排除中的单步依赖关系提取。在RESUME数据集上，所提出的多回合QA模型也取得了最佳性能

# 1 Introduction

在任务形式化和算法方面都有几个关键问题。

- 在形式化层面，REL(e1, e2)三联体结构不足以完全表达文本背后的数据结构。
  - 以Musk案为例，标签之间有一个层次性的依赖关系：时间的提取取决于职位，因为一个人可以在不同的时间段在一个公司担任多个职位。职位的提取也取决于公司，因为一个人可以为多个公司工作。
- 算法层面，神经模型很难捕捉到这种形式化的所有词汇、语义和句法线索，尤其是当(1)实体距离较远；(2)一个实体涉及多个三联体；或(3)关系跨度有重叠时。

---

在本文中，我们提出了一个新的范式来处理实体-关系的提取任务。我们将该任务形式化为一个多轮的问题回答任务：每个实体类型和关系类型都由一个问题回答模板来表征，实体和关系通过回答模板问题来被提取。答案是文本跨度，使用现在标准的机器阅读理解（MRC）框架提取：预测给定上下文的答案跨度。为了提取像表1这样的结构性数据，该模型需要依次回答以下问题：

- Q: who is mentioned in the text? A: Musk;
- Q: which Company/companies did Musk work for? A: SpaceX, Tesla, SolarCity, Neuralink and The Boring Company;
- Q: when did Musk join SpaceX? A: 2002;
- Q: what was Musk’s Position in SpaceX? A: CEO.

将实体关系提取任务视为多轮QA任务有以下主要优势：

1. 多轮QA设置提供了一种优雅的方式来捕捉标签的层次依赖性。随着多轮QA的进行，我们逐步获得我们在下一轮所需要的实体。这与多轮填空对话系统（Williams and Young, 3e.g., 在文本A B C D中，（A，C）是一对，（B，D）是一对。2005；Lemon等人，2006）；
2. 问题查询编码了我们要识别的关系类的重要先验信息。这种信息性可以潜在地解决现有的关系提取模型不能解决的问题，比如相距遥远的实体对，关系跨度重叠等；
3. QA框架提供了一种自然的方式来同时提取实体和关系：大多数MRC模型支持输出特殊的NONE标记，表示问题没有答案。

通过这一点，原来的两个任务，实体提取和关系提取可以合并为一个单一的QA任务：如果一个关系对应的问题的返回答案不是NONE，那么这个关系就成立，而这个返回的答案就是我们想要提取的实体。

在本文中，我们展示了所提出的范式，该范式将实体-关系提取任务转化为多轮QA任务，比现有的系统引入了显著的性能提升。它在ACE和CoNLL04数据集上实现了最先进的（SOTA）性能。这些数据集上的任务被形式化为三联体提取问题，其中两轮QA就足够了。因此，我们建立了一个更复杂、更困难的数据集，名为RESUME，要求从原始文本中提取个人的传记信息。从RESUME中构建结构性知识库需要四到五轮的质量保证。我们还表明，这种多轮QA设置可以很容易地整合强化学习（就像在多轮对话系统中一样）以获得额外的性能提升。

# 2 Related Work

## 2.1 Extracting Entities and Relations

许多早期的实体-关系提取系统是流水线式的（Zelenko等人，2003；Miwa等人，2009；Chan和Roth，2011；Lin等人，2016）：实体提取模型首先识别感兴趣的实体，然后关系提取模型构建所提取实体之间的关系。虽然流水线系统具有整合不同数据源和学习算法的灵活性，但它们在错误传播方面受到很大影响。为了解决这个问题，人们提出了联合学习模型。早期的联合学习方法通过各种依赖关系将两个模型连接起来，包括通过整数线性编程解决的约束条件（Yang和Cardie，2013；Roth和Yih，2007），卡片金字塔解析（Kate和Mooney，2010），以及全局概率图形模型（Yu和Lam，2010；Singh等人，2013）。

在后来的研究中，Li和Ji（2014）使用结构化感知器与高效的beamsearch提取实体提及和关系，与基于约束的方法相比，效率明显提高，耗时减少。Miwa和Sasaki（2014）；Gupta等人（2016）；Zhang等人（2017）提出了填表法，这为将更复杂的特征和算法纳入模型提供了机会，例如解码中的搜索顺序和全局特征。神经网络模型在文献中也被广泛使用。Miwa和Bansal（2016）介绍了一种端到端的方法，使用具有共享参数的神经网络模型提取实体及其关系，即使用神经标签模型提取实体，使用基于树状LSTMs的神经多类分类模型提取关系（Tai等人，2015）。Wang等人（2016a）使用多级注意力CNN提取关系。Zeng等人（2018）提出了一个新的框架，使用序列到序列模型来生成实体-关系三元组，自然地结合了实体检测和关系检测。

绑定实体和关系提取模型的另一种方式是使用强化学习或最小风险训练，其中训练信号是根据两个模型的联合决策来给出。Sun等人（2018）在最小风险训练的框架工作下，优化了一个全局损失函数来联合训练这两个模型。Takanobu等人（2018）使用分层强化学习，以分层方式提取实体和关系。 

## 2.2 Machine Reading Comprehension

主流的MRC模型（Seo等人，2016；Wang和Jiang，2016；Xiong等人，2017；Wang等人，2016b）提取给定查询段落中的文本跨度。文本跨度提取可以简化为两个多类分类任务，即预测答案的开始和结束位置。类似的策略可以扩展到多段式MRC（Joshi等人，2017；Dunn等人，2017），其中答案需要从多个段落中选择。多段式MRC任务可以通过串联段落轻松简化为单段式MRC任务（Shen等人，2017；Wang等人，2017b）。Wang等人（2017a）首先对段落进行排序，然后在选定的段落上运行单段式MRC。Tan等人（2017）将段落排名模型与阅读理解模型联合训练。像BERT（Devlin等人，2018）或Elmo（Peters等人，2018）这样的预训练方法已被证明对MRC任务有极大的帮助。

一直以来，人们倾向于将非QA NLP任务铸造成QA任务（McCann等人，2018）。我们的工作受到Levy等人（2017）的高度启发。Levy等人（2017）和McCann等人（2018）专注于识别两个预定义实体之间的关系，作者将关系提取的任务正式化为一个单一的QA任务。在本文中，我们研究了一个更复杂的场景，即需要对层次化的标签依赖性进行建模，sigle-turn QA方法不再足够。我们表明，我们的multi-turn QA方法能够解决这一挑战，并获得新的最先进的结果。

# 4 Model

## 4.1 System Overview

该算法的概述见算法1。该算法包含两个阶段：

<img src="https://s2.loli.net/2023/04/12/aethnfd6curgiRq.png" alt="image-20230412174210381" style="zoom: 53%;" />

（1）头部实体提取阶段（第4-9行）：多轮QA的每个情节都由一个实体触发。为了提取这个起始实体，我们使用`EntityQuesTemplates`**将每个实体类型转化为一个问题**（第4行），实体 $e$ 是通过回答问题提取的（第5行）。如果系统输出特殊的NONE标记，那么就意味着s不包含该类型的任何实体。

(2) 关系和 tail-entity 提取阶段（第10-24行）： `ChainOfRelTemplates` 定义了一个**关系链**，我们需要按照这个顺序来运行多轮QA。原因是，一些实体的提取取决于其他实体的提取。例如，在RESUME数据集中，一个高管所担任的职位依赖于他所工作的公司。同样，对时间实体的提取也依赖于对公司和职位的提取。提取的顺序是手动预先定义的。`ChainOfRelTemplates`还**为每个关系定义了模板**。每个模板都包含一些需要填充的槽。

- 为了生成一个问题（第14行），我们将先前提取的实体插入到模板的槽中。
- 关系REL和尾部实体 $e$ 将通过回答生成的问题（第15行）被联合提取出来。
- 返回的NONE标记表示在给定的句子中没有答案。

值得注意的是，从 head-entity 提取阶段提取的实体不一定都是头实体。在随后的关系和尾部实体提取阶段，从第一阶段提取的实体最初被认为是头部实体，并被送入模板以生成问题。如果从第一阶段提取的实体 $e$ 确实是一个关系的头部实体，那么QA模型将通过回答相应的问题来提取尾部实体。否则，答案将是NONE，从而被忽略。

对于ACE04、ACE05和CoNLL04数据集，只需要两个QA回合。对于RESUME，我们需要提取4个实体，因此ChainOfRelTemplates包含3个链。

## 4.2 Generating Questions using Templates

每个实体类型都与模板生成的特定类型的问题有关。有两种方法可以基于模板生成问题：自然语言问题或伪问题。伪问题不一定符合语法。例如，设施类型的自然语言问题可能是文本中提到的哪个设施，而伪问题可能只是实体：设施。

在关系和尾部实体联合提取阶段，通过将关系特定的模板与提取的头部实体结合起来，产生一个问题。该问题可以是一个自然语言问题，也可以是一个伪问题。例子见表3和表4。

## 4.3 Extracting Answer Spans via MRC

##  

























