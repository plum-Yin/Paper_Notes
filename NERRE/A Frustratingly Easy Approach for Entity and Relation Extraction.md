# Abstract

端到端关系提取旨在识别命名实体并提取它们之间的关系。最近的工作将这两个子任务联合建模，要么将它们投射到一个结构化的预测框架中，要么通过共享表示执行多任务学习。

在这项工作中，我们提出了一种简单的实体和关系提取的流水线方法，并在标准基准(ACE04, ACE05和SciERC)上建立了最新的技术，与先前使用相同预训练编码器的联合模型相比，关系F1的绝对改进为1.7%-2.8%。我们的方法基本上建立在两个独立的编码器上，并且仅仅使用实体模型来构造关系模型的输入。通过一系列仔细的检查，我们验证了学习实体和关系的不同上下文表示、在关系模型的早期融合实体信息以及结合全局上下文的重要性。最后，我们还提出了一种有效的近似方法，该方法在推理时只需要实体和关系编码器的一次传递，实现8-16倍的加速，但精度略有降低。

# Introduction

我们的实体模型建立在跨度级表示的基础上，而我们的关系模型建立在特定于给定跨度对的上下文表示的基础上。尽管它很简单，但我们发现这种流水线方法非常有效。

为了更好地理解这种方法的有效性，我们进行了一系列仔细的分析。我们观察到，(1)实体和关系模型的上下文表示本质上捕获不同的信息，因此**共享它们的表示会损害性能**;(2)在关系模型的输入层融合实体信息(边界和类型)至关重要;(3)利用跨句信息在这两个任务中都很有用。

因此，我们期望这个简单的模型将作为端到端关系提取的一个非常强大的基线，并使我们重新思考实体和关系联合建模的价值。最后，我们的方法的一个可能的缺点是，我们需要为每一对实体运行一次关系模型。为了缓解这一问题，我们提出了一种新颖有效的替代方案，即在推理时对不同组实体对进行近似和批处理计算。这个近似实现了8-16倍的加速，而精度只有轻微的降低(例如，在ACE05上F1下降1.0%)，这使得我们的模型在实践中使用起来又快又准确。我们的最终系统被称为PURE(普林斯顿大学关系提取系统)，我们将代码和模型公开提供给研究社区。

我们的贡献总结如下:

- 我们提出了一种简单有效的端到端关系提取方法，该方法学习了两个独立的编码器，用于实体识别和关系提取。我们的模型在三个标准基准上建立了最先进的新技术，**超越了所有以前的联合模型**。
- 我们进行仔细的分析，以了解为什么我们的方法表现如此之好，以及不同的因素如何影响最终的表现。我们得出的结论是，**学习实体和关系的不同上下文表示比共同学习它们更有效**。
- 为了加快我们模型的推理时间，我们还提出了一种新的高效近似，它在很小的精度下降的情况下实现了很大的运行时间改进。

# Method

## Problem Definition

### NER

$\mathcal{E}$ 是一系列预先定义的**实体类型**

span $s_i\in S$, span $s_i$ is not an entity

任务是，对于每个跨度 $s_i\in S$，预测实体类型 $y_e(s_i)\in\mathcal{E}$ or $y_e(s_i)=\epsilon$

任务的输出是 $Y_e=\{(s_i,e):s_i\in S,e\in\mathcal{E}\}$

### RE

$\mathcal{R}$ 是一系列预先定义的**关系类型**

任务是，对于每对跨度 $s_i\in S,\;s_j\in S$，预测一个关系类型 $y_r(s_i,s_j)\in \mathcal{R}$，或者它们之间没有关系 $y_r(s_i,s_j)\in \epsilon$

,任务的输出是 $Y_r=\{(s_i,s_j,r):s_i,s_j\in S,r\in\mathcal{R}\}$

## 3.2 Approach

![image-20230427224057165](https://s2.loli.net/2023/04/27/Sl3QgviNphfCcT2.png)

- (a) Our entity model predicts all the entities at once.  
- (b) Our relation model considers every pair of entities independently by inserting typed entity markers (e.g., `[S:MD]`: the subject is a `METHOD`, `[O:TK]`: the object is a `TASK`).   
- (c) We also proposed an approximation relation model which supports batch computations. The tokens of the same color share the positional embeddings (see Section 4.3 for more details).

如图1所示，我们的方法由实体模型和关系模型组成。实体模型首先接受输入句子，并预测每个跨度的实体类型(或)。然后，我们通过插入额外的标记令牌来突出显示subject和object及其类型，从而在关系模型中独立处理每一对候选实体。我们将在下面详细介绍每个组件，最后总结我们的方法与DYGIE++之间的差异。

---

这种使用额外标记来突出主客体的想法并不是全新的，因为它最近在关系分类中得到了研究(Zhang等人，2019;Soares等人，2019;Peters et al.， 2019)。然而，大多数关系分类任务(例如，TACRED (Zhang et al.， 2017b))只关注输入句子中的一对给定的主语和宾语，其有效性尚未在端到端设置中进行评估，我们需要对多个实体提及之间的关系进行分类。

我们在实验中观察到很大的改进(第5.1节)，这加强了我们的假设，即在一个句子中对不同实体对之间的关系建模需要不同的上下文表示。Zhang et al. (2019);Soares等人(2019)只考虑无类型标记(例如< S >， < /S >)和之前的端到端模型(例如(Wadden et al.， 2019))，只通过辅助损失将实体类型信息注入关系模型。

我们发现在输入层注入类型信息对于区分实体类型非常有帮助——例如，在试图理解关系之前，判断“Disney”是指一个人还是一个组织。

---

跨句上下文

跨句信息可用于帮助预测实体类型和关系，特别是代词提及。Luan et al. (2019);Wadden等人(2019)采用了一种传播机制来整合交叉句上下文。Wadden等人(2019)也添加了一个3句话的上下文窗口，这被证明可以提高性能。我们还评估了在我们的方法中利用跨句上下文的重要性。由于我们期望预训练的语言模型能够捕获远程依赖关系，我们简单地通过将句子扩展到实体和关系模型的固定窗口大小W，来合并跨句子上下文。

具体来说，给定一个有n个单词的输入句子，我们分别从左上下文和右上下文中增加(W−n)/2个单词。

---

预测的实体 $y_e(s_i)=\arg\max_{e\in\mathcal{E}\cup\{\epsilon\}}P_e(e|s_i)$

预测的非空实体 $S_{\rm pred}=\{s_i:y_e(s_i)\not= \epsilon\}$

通过 $y_e(s_i)$ 和 $y_e(s_j)$ 构造关系模型 $P_r(r|s_i,s_j)$ 的输入

---

3.3 Efficient Batch Computations

我们的方法的一个可能的缺点是，我们需要为每一对实体运行一次关系模型。为了缓解这个问题，我们提出了一种新的、有效的替代关系模型。关键的问题是，我们希望在同一个句子中对不同的跨度对重复使用计算。这在我们的原始模型中是不可能的，因为我们必须为每对跨度独立地插入实体标记。为此，我们提出了一个近似模型，对原来的关系模型做了两个主要的改变。

首先，我们没有直接将实体标记插入到原始句子中，而是将标记的**位置嵌入**与相应span的开始和结束标记联系起来:



其次，我们给注意层添加了一个约束。我们强制文本令牌只关注文本令牌而不关注标记令牌，而实体标记令牌可以关注所有文本令牌和与同一span对关联的所有4个标记令牌。

这两个修改允许我们重用所有文本令牌的计算，因为文本令牌的表示独立于实体标记令牌。因此，我们可以在关系模型的一次运行中批量处理来自同一句子的多对跨。

在实践中，我们将所有标记符号添加到句子的末尾，以形成对一组span对进行批处理的输入(图1(c))。这将导致在推理时获得很大的加速，而性能只会有很小的下降(第4.3节)。



# Conclusion

本文提出了一种简单有效的端到端关系提取方法。我们的模型独立学习了两个用于实体识别和关系提取的编码器，我们的实验表明，它在三个标准基准上大大优于以前的最先进技术。我们进行了广泛的分析，以了解我们的方法的优越性能，并验证学习实体和关系的不同上下文表示以及使用实体信息作为关系模型的输入特征的重要性。我们还提出了一个有效的近似，在推理时获得了很大的加速，而精度降低很小。我们希望这个简单的模型可以作为一个非常强大的基线，让我们重新思考联合训练在端到端关系提取中的价值。

















