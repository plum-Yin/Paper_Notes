# Abstract

数据量在探索前沿材料方面的意义越来越大，一些数据集已经通过手工或自动方法生成。然而，材料科学领域很难有效地利用大量的数据，特别是在应用学科中，对材料的评估是基于设备性能而不是其属性。

本文提出了一个新的自然语言处理（NLP）任务，称为结构化信息推理（SII），以解决材料科学中器件层面信息提取的复杂性。

我们通过在现有的过氧化物太阳能电池FAIR（Findable, Accessible, Interoperable, Reusable）数据集上调整GPT-3来完成这项任务，其F1分数为91.8%，并将该数据集与自其发布以来的数据进行了扩展。产生的数据经过格式化和规范化处理，使其能够在后续的数据分析中直接作为输入使用。这一特点使材料科学家能够通过选择他们领域内的高质量评论文章来开发模型。此外，我们设计了一些实验来预测太阳能电池的电性能，并使用大型语言模型（LLMs）设计具有目标参数的材料或设备。我们的结果证明了与传统的机器学习方法在没有特征选择的情况下的可比性，突出了大型语言模型在获取科学知识和设计新材料方面与材料科学家相似的潜力。

# Introduction

尽管人们广泛认识到数据的重要性，并不断采取举措利用其潜力，但实验材料科学领域在有效利用大量的可用数据方面一直遇到困难[5]。这个问题在应用学科中尤其明显，在这些学科中，对材料的评价往往主要是基于它们的设备性能，而不是对其固有属性和行为的全面理解[6]。

在这种情况下，一个关键问题是从广泛的、非结构化的科学文献中熟练地提取相关信息。这一挑战不仅阻碍了对候选材料及其属性的全面了解，而且也阻碍了对未来应用的识别。它还造成了材料发现管道的瓶颈，其中实验合成仍然是费力和耗时的。

---

自然语言处理（NLP）技术，特别是命名实体识别（NER），已被证明有希望解决这些问题，提供了简化从科学文献中提取相关信息的潜力。然而，最重要的是，它们仍然不能在设备层面进行信息提取，因为一个设备在每个材料和实体之间有复杂的关系。在这项研究中，我们引入了一个新的NLP任务，称为结构化信息推理（SII），以利用材料科学中预先存在的评论论文数据集。这项任务处于话语层面，在实践中，涵盖了主流任务，如NER、实体解析（ER）、关系提取（RE）和信息推理（II）。

我们通过在2021年2月发布的人工总结的过氧化物太阳能电池FAIR（Findable, Accessible, Interoperable, Reusable）数据集上对GPT-3进行微调，一步到位地完成了这项复杂的任务[7]。我们的微调模型不仅表现出高精度，而且拥有自动更新所有来自评论论文的科学数据集的能力。我们在非常活跃的过氧化物太阳能电池领域展示了这种新颖的方法，并成功地提取了错综复杂的关系，并在2021年3月至2023年3月构建了一个其他过氧化物太阳能电池设备级知识的图网络。

我们的方法提供了证据，证明LLM可以自主地学习复杂的知识数据框架，并作为预定义的模式从评论论文中构建输出，而无需额外的人工注释。产生的数据集经过格式化和规范化处理，使其能够在后续的数据分析（如机器学习）中直接作为输入使用，而无需处理步骤。

这一功能将使材料科学家能够通过在他们的领域内选择高质量的评论文章来开发他们自己的模型。此外，LLM API可以直接在个人电脑上使用，以完成广泛的复杂的材料信息学任务，取代昂贵的自定义和本地化语言模型的后期训练过程。

# Related Work

一些数据集[19, 20, 21]采用了NER来产生自动生成的材料属性数据的表格数据库，这些数据是由文本条目聚合而成的。

尽管做出了这些努力，实验材料科学的很大一部分仍然面临着**有效利用生成的数据**的挑战，特别是在应用领域，材料的评估主要是基于它们在设备中的性能。这就需要对文本条目之间的关系进行提取。

提取材料科学中实体之间的关系一直是一个挑战，与NER任务相比，受到的关注相对较少。Mysore等人[22]建立了一个由230个合成程序组成的数据集，该数据集带有标记图。其节点是合成操作及其类型化的参数，而标记的边则是节点之间的关系。MatSciBERT[23]在这个数据集上产生了RE的最佳性能。

大多数现有的研究将RE视为信息检索管道中NER之后的步骤，并且通常关注句子内部的二元关系[24]。因此，在这些基于管道的系统中，RE本质上是一个对已识别实体的分类任务[25, 26]。然而，现实世界的情况要比这个基本的背景复杂得多。最近在RE研究方面的进展集中在解决更复杂的RE场景，如涉及多个句子的场景[24]。值得注意的是，N次方关系（N个实体参与一个关系），有更多的 挑战，已经受到越来越多的关注。最近，[27]提出了一种序列到序列的大型语言模型（seq2seq-LLM）方法，能够处理复杂的相互关系，而不需要列举所有可能的N-ary关系。他们对OpenAI[28]开发的著名LLM GPT-3进行了微调，以联合执行NER和RE任务，旨在提取层次化的实体关系。

## Issues of traditional annotation mechanism

上面提到的研究使用了一个逐字的传统注释机制（见图1），这与材料科学家的需求不一致。一方面，这种机制通常要求自然语言处理和材料科学专家在几个方面做出大量努力： 1）创建NER类别；2）开发标签界面；3）与NER/RE标签规则相关的学习成本；以及4）NER/RE标签的时间成本。相反，科学信息往往超越了实体之间的简单配对关系。例如，一个化合物的特性是由多种因素决定的，如材料名称、相结构、形态和合成方法。这种复杂性体现在 "PECVD（等离子体增强化学气相沉积）Al-doped TiO2薄膜 "和 "ALD（原子层沉积）Al-doped TiO2 "之间的区别，它们表现出不同的性能。此外，材料知识经常是分层次的，其关系可能只在一个实体类型和一个由多个实体和关系组成的复合实体之间有效。从理论上讲，这种关系可以被建模为N-ary，但是全面列举所有可能的变化既不现实，也不适合传统的关系提取方法，因为每种关系类型都需要足够数量的训练实例。

由于材料信息的注释和模拟的难度，高质量的注释数据在整个材料科学中是有限的，促使我们利用现有的评论文章数据库。一篇评论文章代表了一种学术出版物，它综合并评估了之前关于特定主题的研究论文。这类文章调查独特的研究问题或理论或实践方法，为读者提供对该研究领域的广泛和最新的了解。这些文章包含了自然的、高质量的总结和特定领域的主题、材料和性能以及设备信息的错综复杂的关系。我们努力通过实体注释和关系注释，将其他科学家提供的评论文章中的总结信息回溯到原文。然而，这些努力并没有导致与相应章节的完美匹配。据统计，精确匹配显示出较低的匹配率，平均为44.7%。未匹配的部分需要出口手动注释，而每个材料条目的注释时间估计为20秒[27]。因此，将这个数据集转换为传统的逐字的NERRE数据注释被证明是具有挑战性的。 

## Opportunities and new NLP task - Structured Information Inference

正如前几节所讨论的，现有的研究主要集中在识别实体和它们的关系上。然而，材料科学家提取信息的实际过程要复杂得多。研究文章中的表达方式错综复杂，多种多样。在设备层面，不仅需要考虑材料之间的复杂关系，而且不同出版物的单位也可能不同。例如，"0.3 cm2 "相当于 "0.003 mm2"。实体的定义可以很灵活，有时其含义取决于不同段落中的词语。一篇论文可能只提到 "Al-doped TiO2"，让科学家推断它是 "ALD "还是 "PECVD "生长的。此外，特定领域的词汇可能会带来歧义，使问题进一步复杂化；例如，"Al-doped TiO2 film "可能与 "AlxTiyO film "同义。我们研究了科学家们用来总结和推断材料科学文章信息的各种现象，发现这些现象可以与现有的NLP任务保持一致，如图2（b）中的例子所示：

- 命名实体识别（NER）： 直接提取信息，如材料名称和温度。
- 实体识别（ER）： 对信息的表达格式、单位、缩写等进行标准化。
- 信息推理（II）： 对信息进行处理和推理。
- 关系提取（RE）： 辨别单个条目或条目组之间的联系。

从科学文本中提取信息可能比一般文本的简单过程更具挑战性。此外，一个材料知识可能是通过多个实体的NLP任务推断出来的。例如，在一篇评论文章或FAIR数据集中，Al-doped TiO2紧密层可以被推断为ALD c-AlxTiyO层。(当沉积方法在另一段中被提及时）。

这些复杂性使得对相关训练数据集的注释要求特别高，特别是在文档层面，因为它们代表了跨越几个世纪的材料科学知识的积累。

为了模拟科学家从特定领域的文本中提取信息的过程，我们提出了一个为科学领域设计的新的NLP任务，称为结构化信息推理（SII）。这个任务旨在联合信息推理（或提取）和关系提取。这种关系可以是分层的，也可以是多个项目的列表，而不需要列举所有可能的n元组关系。==最初，我们尝试使用基于BERT的方法。但是，由于需要确定每条信息的具体任务，使问题变得复杂，使得原始的BERT或特定领域的BERT不适合进行微调。==

然而，GPT-3的出现及其相关应用提供了新的机会。如图2(a)所示，GPT-3和其他生成性语言模型采用解码器结构，非常适合seq-to-seq任务（即输入文本生成输出文本），并与材料科学家从文献中收集数据的生成逻辑相一致。因此，我们建议对GPT-3[28]进行微调，直接从原始论文中推断关键信息。这种方法不仅可以节省大量的时间和成本，而且可以使信息的总结更加准确和全面。GPT-3模型可以捕捉论文中的高维信息和关系，而传统的逐字标记机制可能会忽略这一点。 

# 3 Methods 

## Dataset background and Graph Network Design

本研究的数据库包含120多万篇关于材料科学和能源主题的全文研究文章，来源是著名的出版商，如Elsevier, Springer Nature和Royal Society of Chemistry。这些文章是以XML/HTML格式提供的。从雅各布森在2022年手工提取的42,000条设备数据记录中，我们将它们与15,000多篇相应的文章联系起来，只关注英文出版物。

原始数据集包含了95个属性，涵盖了stack 信息、system-level 数据和性能指标。这些信息随后被整合到一个图形网络中，如图2（c）所示。这些信息被组织成两个层面：material & property 层面的信息和 device 层面的信息（详情可参见附录B）。

---

材料和属性级信息：a. 各层的stack信息（A组）和methods信息（B组），包括基底、电子传输层（ETL）、过氧化物、空穴传输层（HTL）和背接触。

Material & Property Level Information: a. stack information (Set A) and methods information (Set B) for each layer, encompassing substrate, electron transport layer (ETL), perovskite, hole transport layer(HTL), and back contact. 

Device Level Information: a. stability (Set C) and electrical (J-V) performance data (Set D).

器件级信息：a. 稳定性（集C）和电气（J-V）性能数据（集D）。

---

虽然原始数据集拥有捕捉400多个属性的能力，但我们的研究重点是那些具有丰富信息和广泛使用的属性。我们进一步将每个实体之间的关系分为两个层次：material & property 或 device connections。

## Schema Design

在微调中，我们将原始表格数据转换为纯文本模式，以促进模型的理解。每个模式都表示为一个字典，其中键表示元素名称，值表示相应的元素。对于每个相关段落，我们的目标是使模型能够学习如何自动准确地总结相应的模式。

为了与直接使用GPT-3.5进行比较，我们进行了 prompt design，以获得尽可能接近原始格式的结果（我们选择不使用原始GPT-3进行比较，因为即使设计良好的提示，模型产生的结果也非常难以破译，通常包含大量重复和无意义的输出）。

经过多次尝试，我们设计了一个prompt，使用带有前缀 “Read the following paragraphs and extract the information below:” 的原始段落和附加的**元素名称列表**。

我们删除了元素名称中的下划线，并添加了一些要求来限制元素名称的长度或内容。例如，我们在元素名称“HTL deposition procedure” 之后添加了“(only name, not details)”。对于需要布尔答案的元素名称，我们将元素名称更改为general questions。例如，我们将“Module”改为“Any Module test?”

## Dataset preparation (fuzzy match mechanism)

对于数据集的准备，我们首先对科学论文全文进行处理，然后提出一种**模糊匹配机制**来计算模式与底层文本之间的匹配率。为了处理科学论文，我们<u>用标题和内容将每个全文分割成不同的部分</u>。

为了满足GPT-3的2049个tokens限制要求(约1500字)，我们只提取了部分标题中包含关键字“experimental”、“materials”、“methods”或“experiment”的部分作为输入，我们发现这些部分是信息量最大的部分。

在提取出每篇科学论文中信息量最大的部分后，

- 我们应用<u>模糊匹配机制</u>来计算样本集中<u>每对模式与提取内容</u>之间的**匹配率**。
- 然后根据计算出的匹配率对样本进行**排序**。

对于**模糊匹配机制**，给定模式与底层内容的匹配率是基于模式中与<u>底层提取内容匹配的每个 key-value pair 的数量</u>除以 key-value pairs 的总数来计算的。

- 更详细地说，给定模式中<u>每个key的value</u>首先被分隔符分割成一个**value list** (例如，'|'，';'，':')，并且schema中的' spin-coating '被' spin-coated '取代。
- 之后，每个key都有一个给定的matching rule。
- 对于给定的key，如果value list中有一个value 根据给定的 matching rule 与 underlyintg content 匹配，则认为这个key-value pair 与 underlying content 匹配。
- 对于key 'ETL_stack_sequence'，如果给定value 中 `-` 之前的整个 string 或 substring 出现在original content 中，则该value和该content匹配。
- 对于键 '`Perovskite_composition_long_form`'和'`Perovskite_composition_short_form`'，如果给定value 是 original content 中 single word 的子集，则该value与content匹配。
- 对于value为“unknown”的key，我们总是将它们视为匹配。
- 对于所有其他keys，如果value出现在original content 中，则该value与 original content 匹配。

为了提高学习效率，我们根据 match rate 对每个底层内容的模式进行排序，并且只选择每个底层内容的第1个schema作为样本。然后根据 schema match rate 对样本进行排序，并选择前400个样本作为训练样本。这些样本的匹配率从100%到85%不等。

## Fine-tuning details

我们选择davinci (175B参数)[28]作为我们的基础模型，因为它是最适合用于微调的GPT-3模型。每个数据示例都有一个prompt和一个completion。具体来说，

- prompt 是从科学论文中提取的文本，其中有几个段落具有 schema 信息。
- completion act 是这些schema的答案，包括31个 “schema name: answer” 形式的key-value pairs。
- ==Schema 是之前给的数据的列表题==

==Code==；`MDP_FAIR/Inverse Design/gpt.ipynb(data processing)`

根据OpenAI CLI工具的建议，我们的数据集被转换为`.jsonl`格式，其中“`\n`”插入在prompt的末尾，“` `”(空格)插入在completion的开始。然后将数据集分为训练集和测试集，分别包含360个和40个样本。

该模型通过OpenAI API训练4个epochs，批处理大小为1，学习率为0.1，prompt loss weight 为0.01。

## Evaluation

我们使用四个分解的子任务，即NER、RE、ER和II，评估了微调模型和GPT-3.5在SII任务中的表现。NER任务的指标评估了输出模式（预测）与目标模式（答案）的匹配程度。输出模式中的每个元素可以被看作是一个实体$E^p$，目标模式中的相应元素可以被看作是一个实体$E^a$。我们通过将实体 $E$ 分离成一组词$S=\{w_1, w_2, w_3, ..., w_k\}$并比较$S^p$和$S^a$之间的差异来设计一个 word-based 测量。分隔符包括"`;`"、"`|`"、"`:`" 和 `>>`。在分离两个实体后，两个集合中的匹配词的数量被计算为真阳性（$S^p\cap S^a$），集合的差异被计算为假阳性（$S^p\backslash S^a$）或假阴性（$S^a\backslash S^p$）。

RE 任务的指标评估输出模式捕获相关元素集之间的内在关系的可能性。根据 3.1 节描述的模式中元素的性质和内部关系，我们构造了三种类型的 relation：`A-B`、`A-C` 和 `ABC-D`。这些关系也通过类似于 NER 使用的基于单词的测量来评分，使用一些正确的搭配。

- 每个搭配是一个 n 元组，将每个涉及的 实体 $E_n$ 的 单词 $w^m_n$ 与关系 $r$ 相关联。

- 对于每种类型的关系，我们可以将预测模式中的搭配汇总为预测关系集（$R^p$），将答案模式中的搭配汇总为答案关系集（$R^a$）。
- 两个关系集中匹配搭配的数量被计为真阳性（$R^p\cap R^a$），搭配差异被计为假阳性（$R^p\backslash R^a$）或假阴性（$R^a\backslash R^p$）。
- 在识别出各种搭配后，使用上述相同的等式（1）、（2）和（3）计算关系提取的度量。

除了基于词的测量，我们还手动评估了 NER 和 RE 的性能。两位具有材料科学领域知识的专家被邀请根据模型的质量手动判断模型的预测。对于元素的每个预测，他们需要从 0（不正确）、1（正确但信息不相关）和 2（正确）中给出分数。当他们对同一个预测有不同意见时，他们会相互协商并给出最终决定。 1和2都被算为正确，以计算人工评估的准确率。然而，评估分数存在差异：使用精确匹配评估时，对于没有 format 训练的 GPT-3.5 过于严格，而手动评估忽略了 format 差异，可能对微调模型不公平（不计算其 ER 和 II 的能力）。因此，我们进一步评估了 II、ER-U（单位实体解析）和 ER-T（术语实体解析）的性能。所选元素未出现在原文中，这意味着它们的目标答案与原文中的相应部分相比在形式、尺度或表达上都有变化（见表3中的示例）。只有与目标答案完全匹配才算正确。

# 4 Results

我们将报告四个部分的结果:NER结果，RE结果，ER和II结果，以及训练集大小的影响。结果表明，我们的fine-tuned model 在NER和RE任务中都优于GPT-3.5，在唯一ER和II任务中也获得了较高的精度。最后，我们研究了训练集大小对训练 token 精度的影响。本节将演示特定于领域的微调的必要性，并为读者提供对模型性能的更全面的理解。

## NER results

表1显示了通过第3.5节中描述的度量和人工评估计算的模式元素匹配的结果。众所周知，GPT-3.5比GPT-3更强大，但我们在GPT-3上进行微调的模型在f1评分上的表现出人意料地超过GPT-3.5 62.9分，在手动评估上的表现则超过了22分。

对于不同集合的NER结果，可以观察到集合D中的元素对两个模型都更具挑战性(人工评价为59.3%和89.3%)。在没有进行微调的情况下，GPT-3.5生成的元素比目标答案要长，特别是在与过程相关的元素中(即使我们试图在提示设计期间施加长度限制)。根据人工评价的统计，GPT-3.5产生的正确预测中约15%具有显著的不相关信息，而我们的微调模型只有4%。

因此，考虑到输出的平均长度，GPT-3.5具有较低的精度和较高的召回率。但是，GPT-3.5在材料科学知识数据集上的召回率仍明显低于经过微调的GPT-3，这意味着GPT-3.5不能直接准确地总结输入段落中的隐藏信息。

相比之下，一个微调模型不仅能准确地找到相应的部分，还能学会总结、归一化甚至演绎。

## RE results

表2报告了RE分数，用于评估输出模式内部元素集的一致性。由于适当的关系必须基于正确提取的实体，因此RE任务的性能受到NER任务性能的影响。因此，这里的RE分数可以被视为NERRE任务的反映，而不仅仅是RE。总体而言，经过微调的模型在所有三种类型的关系提取中都显著优于GPT-3.5。

具体而言，经过微调的模型从NER到NERRE任务的性能下降(约5%)远远小于GPT-3.5的性能下降(约20%)。对于经过微调的模型，精度和召回率之间的差异也较小(约4%)。在三类关系中，ABC-D关系的表现相对最差(F1-score最低)，这可能是由于d集NER表现较差，涉及的实体较多。在ABC-D关系提取中，经过微调的模型f1得分明显较低，但在人工评价中得分与其他类型相当。相比之下，经过微调的模型在这三种关系中表现得更为平衡。

## II and ER results

表3分别显示了II、ER-U(单位实体分辨率)和ER-T(术语实体分辨率)在我们的微调模型上的支持度和准确性。为了帮助理解，我们还给出了示例prompt和output。对于这些任务，我们没有显示GPT-3.5模型的结果，因为每个任务的准确性为0%或接近0%。相比之下，通过对模型进行微调获得了较高的精度，表明该模型不仅可以完成ER和II任务，而且性能良好。这表明，微调可以极大地增强GPT-3模型理解数据格式和填充缺失信息的能力，模拟科学家从研究论文中提取和处理数据的过程。

## Effect of the training dataset size

流逝的令牌(模型到目前为止看到的令牌数量)和训练令牌精度(模型正确预测的训练批中令牌的百分比)之间的关系如图4(a)所示。图4(b)绘制了经过的示例(模型到目前为止看到的示例数量)和训练损失(训练批上的损失)之间的关系。由于我们将epoch的个数设置为4，因此可以重复以上360的例子。可以观察到，在前50个示例中，训练令牌的准确性急剧增加，训练损失急剧减少，这意味着GPT-3可以在展示给它的少数模式中非常快速地学习生成模式的过程。在100个以上的例子中，增加数据量带来的性能提升是相对缓慢和边际的。

# 5 Discussion

## Comparison of performance

基于预测模式，我们总结了直接使用GPT-3.5的问题:

1)生成不稳定:预测模式有时会遗漏一两个元素(我们在评估时将这些遗漏的元素视为不正确的答案)。

2)建议的模式还可以改变生成答案的表达式，例如，“Backcontact supplements compounds”变成了“Backcontact supplements /compounds”。

3)同一个答案可能有多个表达式，如“未提到”、“N/A”、“未提到”、“未指定”等，导致解析和预测统一格式困难。

4)可变长度:生成的答案的长度不是固定的，有时可能非常长，即使提示设计限制了长度(限制并不总是有效)。

5)在正确答案的表达上做不必要的改变，比如把“60分钟”改成了“1小时”。

6)重复回答，内容相似。

7)有时会出现幻觉(详见LLM材料和器件预测部分)。

相比之下，微调具有显著的优势:1)该领域的顶级专家设计框架，更符合特定领域的实验思维;2)节省了标注的成本、时间和精力;3)相关领域的专业人员可以直接使用相同框架的结果，而不需要任何额外的学习成本。

## Material & Device Prediction with LLM

在对结果进行进一步调查后，我们在集合D中的大型语言模型(LLM)输出中确定了一种被称为“幻觉”的现象。在这种情况下，“幻觉”指的是输入中没有提到稳定性测试，但使用了微调的SII模型的实例。我们设计了两个任务来量化模型的性能:用于预测性能数据的回归和分类任务。

然而，由于只有11%的训练设备数据进行了稳定性测试，样本量不足以生成足够的训练集和测试集。因此，我们选择电性能数据，因为所有数据点都具有相关的值，包括开路电压、$V_{oc}$、短路电流、$J_{sc}$、填充因子、FF和功率转换效率PCE，值得注意的是，模型只预测了AM1.5下 `JV_light_spectra` 和``JV_light_intensity` 等于 $1000\;W/m^2$ 的数据点。

### 分类

我们的第一个任务需要一个分类挑战，旨在评估经过微调的GPT在AM1.5光谱和1000 W/m2光强下准确识别钙钛矿太阳能电池PCE水平的能力，同时考虑诸如堆叠和方法信息等具体参数。

我们将PCE水平分为四组:低(0%-8%)，正常(8%-18%)和高(&gt;18%)。我们期望模型生成与这四个类别对应的文本补全。附录C提供了概述钙钛矿太阳能电池的结构和合成的综合示例方案。图5说明了经过微调的GPT模型在MDP任务中的性能。

### 回归

一项比分类更艰巨的任务涉及开发一个回归模型，能够预测使用特定合成方法的钙钛矿太阳能电池的连续属性值，包括Voc、Jsc、FF和PCE。尽管大型语言模型不能在高度精确的回归任务中预测实数，但它们仍然可以通过在训练中使用四舍五入的值来产生可接受的准确性预测。对于电气性能数据，两个小数点的精度被认为是足够的。附录C给出了一个详细的示例模式。表4和图6展示了MDP中用于回归任务的经过微调的GPT模型的性能。

## Potential of LLM in MDP tasks

LLM在MDP任务中的潜力我们的研究表明，即使没有事先在材料科学方面的培训，LLM也可以预测文献中可能没有明确说明的器件性能数据。虽然产生的幻觉信息并不完全准确，但对于使用积累的科学知识的研究人员来说仍然是有价值的。Liu等人最近在钙钛矿太阳能电池预测方面取得了进展，他们从2735份出版物中手动收集了814个数据点，并仅使用13个特征构建了用于J-V性能预测的机器学习模型，相比之下，llm能够自动生成高维数据集。

这种能力允许LLMs在材料层面指导后续器件设计，考虑退火时间、退火温度、材料厚度和面积等参数，在特征选择上具有更大的灵活性。特征值不仅限于数字，而且很容易被科学家获得。

Jablonka等人[30]还证明，当面对有限的数据时，GPT-3的表现与传统技术相当或优于传统技术，特别是对于具有独特线编码的有机化合物，如SMILES[31]或自拍[32]。同样，我们设计了一个基于哈佛光伏(HOPV15)[33]数据集的模式来预测有机光伏器件(OPV) PCE(密度泛函理论，DFT，计算)。与Meftahi等人[34]采用的BRANNLP(带有拉普拉斯先验的贝叶斯正则化人工神经网络)方法相比，微调GPT通过简单的模式设计实现了类似的性能(详细信息可在附录D中找到)。

LLM，如本研究中使用的GPT-3，已经表现出识别新材料和先前研究的材料之间结构和性能相关相似性的能力，类似于经验丰富的材料科学家的专业知识。这种识别相似性的能力使得探索这些新材料的变化成为可能，从而为创新应用提供了机会。此外，llm展示了通过利用详细的材料信息来设计尖端设备的潜力。虽然GPT-3最初并不是为科学领域量身定制的，但它在这一领域的表现表明LLMs在科学任务中的前景广阔。通过对LLMs进行相关科学文献的进一步培训，他们最终可能被授权指导实验设计，并大大拓宽他们在材料科学及其他领域的应用范围。

## Limitation

# 6 Conclusion







