





# Introduction



在这种情况下，给定目标性能水平，首选模型不是训练速度最快的，而是推理速度最快的，尽管训练大型模型以达到特定性能水平可能更便宜，但训练时间较长的小型模型最终在推理方面更便宜。例如，尽管Hoffmann等人(2022)建议在200B个tokens上训练10B模型，但我们发现即使在1T个tokens之后，7B模型的性能仍在继续提高。